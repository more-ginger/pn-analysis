{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create temporaray csv file for the entire year of coverage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook should be the first one running. It takes all the files in `input_data` and combines them in a csv that spans through 1 year of data. The data used as source should have the same structure in order to be combined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NYT Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to the input-data folder\n",
    "input_data_folder = '../input-data/nyt'\n",
    "\n",
    "# List all files in the input-data folder\n",
    "files = os.listdir(input_data_folder)\n",
    "\n",
    "# Initialize an empty list to store dataframes\n",
    "dataframes = []\n",
    "\n",
    "# Loop through each file and read it into a dataframe\n",
    "for file in files:\n",
    "    file_path = os.path.join(input_data_folder, file)\n",
    "    df = pd.read_json(file_path)\n",
    "    dataframes.append(df)\n",
    "\n",
    "# Concatenate all dataframes into one unique dataframe\n",
    "full_year_nyt = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "# Display the unique dataframe\n",
    "full_year_nyt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zeit Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to the input-data folder\n",
    "input_data_folder = '../input-data/zeit'\n",
    "\n",
    "# List all files in the input-data folder\n",
    "files = os.listdir(input_data_folder)\n",
    "\n",
    "# Initialize an empty list to store dataframes\n",
    "dataframes = []\n",
    "\n",
    "# Loop through each file and read it into a dataframe\n",
    "for file in files:\n",
    "    file_path = os.path.join(input_data_folder, file)\n",
    "    df = pd.read_json(file_path)\n",
    "    dataframes.append(df)\n",
    "\n",
    "# Concatenate all dataframes into one unique dataframe\n",
    "full_year_zeit = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "# Display the unique dataframe\n",
    "full_year_zeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_year_zeit[\"body\"] = full_year_zeit[\"body\"].apply(lambda x: x.replace(\"\\n\", \"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Match Zeit and NYT columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data do not match. This section creates the same column structure for both datasets. It can be skipped if different datasets are needed.\n",
    "ðŸš¨: the structure of specific rows remain unchanged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_year_nyt.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_year_zeit.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mapping of NYT -> Zeit columns, `-` columns will be dropped.\n",
    "- abstract -> -\n",
    "- web_url -> url\n",
    "- snippet -> body\n",
    "- lead_paragraph -> -\n",
    "- print_section -> -\n",
    "- print_page -> -\n",
    "- source -> source\n",
    "- multimedia -> image\n",
    "- headline -> title\n",
    "- keywords -> keywords\n",
    "- pub_date -> dateTimePub\n",
    "- document_type -> dataType \n",
    "- news_desk -> -\n",
    "- section_name -> - \n",
    "- byline -> authors\n",
    "- type_of_material -> -\n",
    "- _id -> uri\n",
    "- word_count -> -\n",
    "- uri -> uri\n",
    "- subsection_name -> -"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove columns that cannot be matched."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_year_nyt = full_year_nyt.drop(columns=[\n",
    "    'abstract',\n",
    "    'lead_paragraph', \n",
    "    'print_section', \n",
    "    'print_page', \n",
    "    'news_desk', \n",
    "    'section_name', \n",
    "    'type_of_material', \n",
    "    'word_count', \n",
    "    'subsection_name', \n",
    "    'uri'\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_year_zeit = full_year_zeit.drop(columns=[\n",
    "    'lang', \n",
    "    'isDuplicate', \n",
    "    'date', \n",
    "    'time', \n",
    "    'dateTimePub', \n",
    "    'sim', \n",
    "    'eventUri', \n",
    "    'sentiment', \n",
    "    'wgt', \n",
    "    'relevance',\n",
    "    'links'\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rename columns to match datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_year_zeit = full_year_zeit.rename(columns={\n",
    "    'url': 'web_url', \n",
    "    'body': 'snippet', \n",
    "    'image': 'multimedia', \n",
    "    'title': 'headline',\n",
    "    'dateTime': 'pub_date',\n",
    "    'dataType': 'document_type',\n",
    "    'uri': '_id',\n",
    "    'authors': 'byline'\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract only main oline headline for NYT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_literal_eval(val):\n",
    "    try:\n",
    "        return ast.literal_eval(val)\n",
    "    except (ValueError, SyntaxError):\n",
    "        return val  # Return the original value if it cannot be parsed\n",
    "\n",
    "full_year_nyt[\"headline\"] = full_year_nyt[\"headline\"].apply(safe_literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_year_nyt[\"headline\"] = full_year_nyt[\"headline\"].apply(lambda x: x[\"main\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract one image url for NYT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_first_url(multimedia_list):\n",
    "    try:\n",
    "        if isinstance(multimedia_list, list) and len(multimedia_list) > 0:\n",
    "            return multimedia_list[0].get(\"url\", None)\n",
    "    except (ValueError, SyntaxError):\n",
    "        return None\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_year_nyt[\"multimedia\"] = full_year_nyt[\"multimedia\"].apply(safe_literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_year_nyt[\"multimedia\"] = full_year_nyt[\"multimedia\"].apply(extract_first_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_year_nyt[\"multimedia\"] = full_year_nyt[\"multimedia\"].apply(lambda x: f\"https://www.nytimes.com/{x}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the Zeit source field to extract newspaper name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_year_zeit[\"source\"] = full_year_zeit[\"source\"].apply(safe_literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_year_zeit[\"source\"] = full_year_zeit[\"source\"].apply(lambda x: x[\"title\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shorten snippet for Zeit data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_year_zeit[\"snippet\"] = full_year_zeit[\"snippet\"].apply(lambda x: x.split('.')[0] + '.' if isinstance(x, str) else x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flatten keywords for NYT data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_year_nyt[\"keywords\"] = full_year_nyt[\"keywords\"].apply(safe_literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_year_nyt[\"keywords\"] = full_year_nyt[\"keywords\"].apply(lambda x: [d[\"value\"] for d in x if isinstance(d, dict)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_year_nyt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Provide same order of columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_year_zeit = full_year_zeit[[\"_id\", \"source\", \"headline\", \"web_url\", \"snippet\", \"multimedia\", \"pub_date\", \"byline\", \"document_type\", \"keywords\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_year_nyt = full_year_nyt[[\"_id\", \"source\", \"headline\", \"web_url\", \"snippet\", \"multimedia\", \"pub_date\", \"byline\", \"document_type\", \"keywords\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define columns that may have dict or list types\n",
    "# This prevents error when posting data to Supabase using psql\n",
    "json_columns = [\"keywords\", \"byline\"]\n",
    "\n",
    "# Convert them to JSON strings\n",
    "for col in json_columns:\n",
    "    full_year_zeit[col] = full_year_zeit[col].apply(json.dumps)\n",
    "    full_year_nyt[col] = full_year_nyt[col].apply(json.dumps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_year_zeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_year_nyt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export data to local folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run to export data to files in a local folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_year_nyt.to_csv(\"../input-data/nyt-temp-data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_year_zeit.to_csv(\"../input-data/zeit-temp-data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post data to Supabase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run to post the data to the [PN Supabase](https://supabase.com/dashboard/project/cvzcwlcdubsgduukqodr)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load variables from .env into environment\n",
    "load_dotenv()\n",
    "\n",
    "# Retrieve values\n",
    "user = os.getenv(\"user\")\n",
    "password = os.getenv(\"password\")\n",
    "host = os.getenv(\"host\")\n",
    "port = os.getenv(\"port\")\n",
    "dbname = os.getenv(\"dbname\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine(f\"postgresql+psycopg2://{user}:{password}@{host}:{port}/{dbname}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_year_nyt.to_sql(\"nyt_articles\", engine, if_exists=\"replace\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_year_zeit.to_sql(\"zeit_articles\", engine, if_exists=\"replace\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
