{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download images from URLs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Important**: This notebook should be run after `create-temp-data.ipynb` if the full year of data needs to be analyzed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The notebook takes a json as input and uses the `requests` module to download the header images for each article. In case of very large datasets, the process can take a long time and use quite some space on the local machine (up to xxx GB). The images are saved into a sub-folder of `/data` called `images`. The folder has been added to the `.gitignore`. If the script needs to be used to run tests or try out analtycal pipelines and task, I suggest using a smaller sample of data (e.g. 1 month)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pandas requests tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import requests.exceptions\n",
    "# parse object-like strings to make them python friendly\n",
    "import ast\n",
    "# helps get the correct format for the image\n",
    "import imghdr\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I load the complete dataset for one year of coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_filename= '../../input-data/temp-data.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dataset = pd.read_csv(input_filename)\n",
    "input_dataset.head(2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assuming we are working with the NYT data, the \"multimedia\" column is an array of objects. The function below transforms the string into a iterable python instance and allows for the extraction of the first url (xlarge image). This procedure will change with data coming from other news outlets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_first_url(multimedia_str):\n",
    "    try:\n",
    "        multimedia_list = ast.literal_eval(multimedia_str)\n",
    "        if isinstance(multimedia_list, list) and len(multimedia_list) > 0:\n",
    "            return multimedia_list[0].get(\"url\", None)\n",
    "    except (ValueError, SyntaxError):\n",
    "        return None\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dataset[\"image_url\"] = input_dataset[\"multimedia\"].apply(extract_first_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dataset[\"image_url\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(input_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All NYT entries are marked by an ID with ambiguous characters: `nyt://interactive/`, the following code uses regex to remove this prefix and retains only the alpha-numeric hash as id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dataset[\"clean_id\"] = input_dataset[\"_id\"].apply(lambda x: x.split('/')[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dataset[\"clean_id\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's where the magic happens ðŸ¤© We iterate over the url of the article and retrieve the image url. Then we use `requests` to download the image to a local folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_images(urls, current_news_outlet):\n",
    "    if not os.path.exists(f'../../data/images/{current_news_outlet}'):\n",
    "        os.makedirs(f'../../data/images/{current_news_outlet}')\n",
    "    \n",
    "    for url in tqdm(urls, desc=\"Downloading images\", unit=\"file\"):\n",
    "        filenameID = url[0]\n",
    "        try:\n",
    "            if current_news_outlet == 'nytimes':\n",
    "                if url[1] != None:\n",
    "                    response = requests.get(\"https://www.nytimes.com/\" + url[1], stream=True)\n",
    "                    if response.status_code != 200:\n",
    "                        print(f\"Download of {url} has failed\")\n",
    "                        exit()\n",
    "                    \n",
    "                    extension = imghdr.what(file=None, h=response.content)     \n",
    "                    filename = f'../../data/images/{current_news_outlet}/{current_news_outlet}-{filenameID}.{extension}'\n",
    "                \n",
    "                    with open(filename, 'wb') as file:\n",
    "                        file.write(response.content)\n",
    "        except requests.exceptions.MissingSchema:\n",
    "            print('URL is not complete')\n",
    "        \n",
    "    \n",
    "    print(f'Download of {current_news_outlet} successful')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Instead of using the whole dataframe, I zip clean id and image_url in a python list, then feed it to the download function\n",
    "list_of_urls = list(zip(*map(input_dataset.get, ['clean_id', 'image_url'])))\n",
    "download_images(list_of_urls, \"nytimes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
