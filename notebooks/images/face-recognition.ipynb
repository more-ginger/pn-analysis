{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top-down face recognition with DeepFace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook implements a top-down solution for face recognition on a given bulk of images. Why top-down? Because it receives a source file with an image of a known person to get similar images from the bulk. The pipeline looks like this:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./assets/img_2.jpg\" alt=\"drawing\" width=\"800\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why is this approach not great? Because we need to define who we want to look for, instead of just getting faces that are similar to each other based on their vector similarity. Moreover, the approach does not work very well as soon as the face is not perfectly visible and is very prone to mistakes based on the image quality, color profile, and other aspects. What we want instead would be an approach that judges human faces based on their similarity, group them in distinct clusters, and simply return the clusters, without straight-up recognizing the subject."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detect and crop faces to reduce noise for facial recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# installs dedicated module for background removal https://github.com/Ir1d/image-background-remove-tool\n",
    "%pip install deepface matplotlib pillow tf-keras seaborn torch pandas opencv-python carvekit --extra-index-url https://download.pytorch.org/whl/cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from deepface import DeepFace\n",
    "from PIL import Image\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from multiprocessing.pool import ThreadPool\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputImage:\n",
    "    def __init__(self, img_name):\n",
    "        self.img = cv2.imread(img_name)\n",
    "        self.__name = img_name\n",
    "\n",
    "    def __str__(self):\n",
    "        return self.__name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download: https://github.com/opencv/opencv_zoo/blob/main/models/face_detection_yunet/face_detection_yunet_2023mar.onnx\n",
    "detector = cv2.FaceDetectorYN.create(\"./utils/face_detection_yunet_2023mar.onnx\",  \"\", (0, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterates over the images in a given folder, detects faces and performs a crop on the face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Iterates over the files in a given folder to perform cropping\n",
    "input_folder = '../../data/images/nytimes/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converts whatever is not a .jpg into a .jpg\n",
    "def convert_img_format_to_jpg(image_path):\n",
    "   with Image.open(image_path) as img:\n",
    "      if img.format != 'JPEG':\n",
    "         rgb_img = img.convert('RGB')\n",
    "         jpg_path = os.path.splitext(image_path)[0] + '.jpg'\n",
    "         rgb_img.save(jpg_path, 'JPEG')\n",
    "         print(f\"Converted {image_path} to {jpg_path}\")\n",
    "         return jpg_path\n",
    "      return image_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_and_crop_faces(image_path, detector, enlargement_factor=2):\n",
    "   # Read input image\n",
    "   loaded_img = InputImage(image_path)\n",
    "   print(loaded_img)\n",
    "   img = loaded_img.img\n",
    "\n",
    "   # Check if the image was loaded correctly\n",
    "   if img is None:\n",
    "      print(f\"Error: Unable to load image at {image_path}\")\n",
    "      return\n",
    "\n",
    "   height, width, _ = img.shape\n",
    "   detector.setInputSize((width, height))\n",
    "   _, faces = detector.detect(img)\n",
    "\n",
    "   # If faces exist\n",
    "   if faces is not None:\n",
    "      # Then crop\n",
    "      for f, face in enumerate(faces):\n",
    "         base_name = os.path.basename(loaded_img.__str__())\n",
    "         name, ext = os.path.splitext(base_name)\n",
    "         unique_face_filename = f\"{input_folder}/detected-faces/{name}{ext}\"\n",
    "         # Available parameters: x1, y1, w, h, x_re, y_re, x_le, y_le, x_nt, y_nt, x_rcm, y_rcm, x_lcm, y_lcm\n",
    "         (x, y, w, h) = face[:4]\n",
    "         x = int(x)\n",
    "         y = int(y)\n",
    "\n",
    "         y1 = max(0, int(y - h * (enlargement_factor - 1) / 2))\n",
    "         y2 = min(height, int(y + h * (1 + (enlargement_factor - 1) / 2)))\n",
    "         x1 = max(0, int(x - w * (enlargement_factor - 1) / 2))\n",
    "         x2 = min(width, int(x + w * (1 + (enlargement_factor - 1) / 2)))\n",
    "         facecrop = img[y1:y2, x1:x2]\n",
    "\n",
    "         cv2.imwrite(unique_face_filename, facecrop)\n",
    "         convert_img_format_to_jpg(unique_face_filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in os.listdir(input_folder):\n",
    "    file_path = os.path.join(input_folder, filename)\n",
    "    if os.path.isfile(file_path):\n",
    "        detect_and_crop_faces(file_path, detector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removes crops that are too small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dir = f\"{input_folder}/detected-faces/\"\n",
    "\n",
    "for filename in os.listdir(img_dir):\n",
    "    filepath = os.path.join(img_dir, filename)\n",
    "    with Image.open(filepath) as im:\n",
    "        x, y = im.size\n",
    "    totalsize = x*y\n",
    "    if totalsize < 12100:\n",
    "        os.remove(filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Face recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's assume we have a folder at `input_data/nyt/source-img/` that contains portraits of known people, like this one:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./assets/beyonce_knowles.jpg\" alt=\"drawing\" width=\"200\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that checks if an image is broken and cannot be opened. If that is the case, it deletes the image.\n",
    "IMAGE_EXT = ('.jpg', '.jpeg', '.png', '.gif')\n",
    "\n",
    "def check_image(image_path):\n",
    "    try:\n",
    "        Image.open(image_path)\n",
    "        print(f'Image is OK: {image_path}')\n",
    "    except:\n",
    "        os.remove(image_path)\n",
    "        print(f'Image deleted: {image_path}')\n",
    "\n",
    "def delete_broken_images(root_dir):\n",
    "    pool = ThreadPool(processes=10)\n",
    "    for subdir, dirs, files in os.walk(root_dir):\n",
    "        for file in files:\n",
    "            if file.endswith(IMAGE_EXT):\n",
    "                image_path = os.path.join(subdir, file)\n",
    "                pool.apply_async(check_image, (image_path,)).get()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We read the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is where you would load the source images for the people that need to be found\n",
    "source_folder = 'input_data/nyt/source-img/'\n",
    "source_images = [f for f in os.listdir(source_folder) if f.endswith(IMAGE_EXT)]\n",
    "print(source_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set up the interface for our model. We use DeepFace to load Facenet512. The \"find_faces\" function takes two parameters: the `img_path` with the portrait of who needs to be found and the `db_path`, a folder with all the images that need to be analyzed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_faces(source_img, db_path): \n",
    "  df =  DeepFace.find(\n",
    "    img_path = source_img,\n",
    "    db_path = db_path,\n",
    "    enforce_detection = False,\n",
    "    model_name = \"Facenet512\"\n",
    "  )\n",
    "  print(f'found images {len(df[0])}')\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "appended_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "for image in source_images: \n",
    "    print(f'Checking {image}')\n",
    "    # Here we run find_faces\n",
    "    data = find_faces(f'{source_folder}/{image}', f\"{input_folder}/detected-faces/\")\n",
    "    if not data[0].empty:\n",
    "        data[0]['source'] = image\n",
    "    appended_data.append(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.concat(appended_data, axis=0)\n",
    "all_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data['source'] = all_data['source'].str.replace('.jpg', '')\n",
    "all_data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_counts = all_data['source'].value_counts()\n",
    "print(source_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the new folder if it doesn't exist\n",
    "politicians_folder = f\"{input_folder}/detected-faces/recognized\"\n",
    "os.makedirs(politicians_folder, exist_ok=True)\n",
    "\n",
    "# Copy each image to the new folder\n",
    "for image_path in all_data['identity']:\n",
    "    shutil.copy(image_path, politicians_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.to_csv(\"../../data/images/nytimes/recognized_faces_nyt.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
