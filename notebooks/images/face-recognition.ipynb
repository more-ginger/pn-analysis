{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top-down face recognition with DeepFace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detect and crop faces to reduce noise for facial recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# installs dedicated module for background removal https://github.com/Ir1d/image-background-remove-tool\n",
    "%pip install torch pandas opencv-python carvekit --extra-index-url https://download.pytorch.org/whl/cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputImage:\n",
    "    def __init__(self, img_name):\n",
    "        self.img = cv2.imread(img_name)\n",
    "        self.__name = img_name\n",
    "\n",
    "    def __str__(self):\n",
    "        return self.__name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download: https://github.com/opencv/opencv_zoo/blob/main/models/face_detection_yunet/face_detection_yunet_2023mar.onnx\n",
    "detector = cv2.FaceDetectorYN.create(\"./utils/face_detection_yunet_2023mar.onnx\",  \"\", (0, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterates over the images in a given folder, detects faces and performs a crop on the face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Iterates over the files in a given folder to perform cropping\n",
    "input_folder = '../../data/images/nytimes/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converts whatever is not a .jpg into a .jpg\n",
    "def convert_img_format_to_jpg(image_path):\n",
    "   with Image.open(image_path) as img:\n",
    "      if img.format != 'JPEG':\n",
    "         rgb_img = img.convert('RGB')\n",
    "         jpg_path = os.path.splitext(image_path)[0] + '.jpg'\n",
    "         rgb_img.save(jpg_path, 'JPEG')\n",
    "         print(f\"Converted {image_path} to {jpg_path}\")\n",
    "         return jpg_path\n",
    "      return image_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_and_crop_faces(image_path, detector, enlargement_factor=2):\n",
    "   # Read input image\n",
    "   loaded_img = InputImage(image_path)\n",
    "   print(loaded_img)\n",
    "   img = loaded_img.img\n",
    "\n",
    "   # Check if the image was loaded correctly\n",
    "   if img is None:\n",
    "      print(f\"Error: Unable to load image at {image_path}\")\n",
    "      return\n",
    "\n",
    "   height, width, _ = img.shape\n",
    "   detector.setInputSize((width, height))\n",
    "   _, faces = detector.detect(img)\n",
    "\n",
    "   # If faces exist\n",
    "   if faces is not None:\n",
    "      # Then crop\n",
    "      for f, face in enumerate(faces):\n",
    "         base_name = os.path.basename(loaded_img.__str__())\n",
    "         name, ext = os.path.splitext(base_name)\n",
    "         unique_face_filename = f\"{input_folder}/detected-faces/{name}{ext}\"\n",
    "         # Available parameters: x1, y1, w, h, x_re, y_re, x_le, y_le, x_nt, y_nt, x_rcm, y_rcm, x_lcm, y_lcm\n",
    "         (x, y, w, h) = face[:4]\n",
    "         x = int(x)\n",
    "         y = int(y)\n",
    "\n",
    "         y1 = max(0, int(y - h * (enlargement_factor - 1) / 2))\n",
    "         y2 = min(height, int(y + h * (1 + (enlargement_factor - 1) / 2)))\n",
    "         x1 = max(0, int(x - w * (enlargement_factor - 1) / 2))\n",
    "         x2 = min(width, int(x + w * (1 + (enlargement_factor - 1) / 2)))\n",
    "         facecrop = img[y1:y2, x1:x2]\n",
    "\n",
    "         cv2.imwrite(unique_face_filename, facecrop)\n",
    "         convert_img_format_to_jpg(unique_face_filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in os.listdir(input_folder):\n",
    "    file_path = os.path.join(input_folder, filename)\n",
    "    if os.path.isfile(file_path):\n",
    "        detect_and_crop_faces(file_path, detector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removes crops that are too small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dir = f\"{input_folder}/detected-faces/\"\n",
    "\n",
    "for filename in os.listdir(img_dir):\n",
    "    filepath = os.path.join(img_dir, filename)\n",
    "    with Image.open(filepath) as im:\n",
    "        x, y = im.size\n",
    "    totalsize = x*y\n",
    "    if totalsize < 12100:\n",
    "        os.remove(filepath)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
